{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully!\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(256,256,3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(Conv2D(128, (3, 3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))         #(2,2) ?\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\",metrics=[\"accuracy\"])\n",
    "print('Model compiled successfully!')\n",
    "model.save(filepath=\"/storage/Manual Model.h5\",\n",
    "               overwrite=True,include_optimizer=True,save_format='h5')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 validated image filenames.\n",
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/storage/data.csv\")\n",
    "df['filename']=\"clips-\"+df[\"id\"].astype(str)+\".png\"\n",
    "\n",
    "df_validate = pd.read_csv(\"/storage/validate.csv\", na_values=['NA', '?'])\n",
    "df_validate['filename']=\"clips-\"+df_validate[\"id\"].astype(str)+\".png\"\n",
    "\n",
    "\n",
    "df_train = df[:40000] #45000 images in total\n",
    "df_test = df[40000:45000]\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGES_DIR = \"/storage/clips\"\n",
    "\n",
    "training_datagen = ImageDataGenerator(rescale = 1./255., horizontal_flip=True, \n",
    "                                      vertical_flip=True, fill_mode='nearest')\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train,\n",
    "        directory=IMAGES_DIR,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"clip_count\",\n",
    "        target_size=(256, 256),\n",
    "        batch_size=8,\n",
    "        class_mode='other')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        directory=IMAGES_DIR,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"clip_count\",\n",
    "        target_size=(256, 256),\n",
    "        class_mode='other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded h5 model!\n",
      "Successfully created callback: Monitor\n",
      "Successfully created callback: Checkpoint\n",
      "Epoch 1/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 9.8017\n",
      "Epoch 00001: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 742s 148ms/step - loss: 9.8022 - val_loss: 3.0160\n",
      "Epoch 2/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 3.5799\n",
      "Epoch 00002: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 720s 144ms/step - loss: 3.5797 - val_loss: 2.7345\n",
      "Epoch 3/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 2.7049\n",
      "Epoch 00003: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 715s 143ms/step - loss: 2.7046 - val_loss: 2.1451\n",
      "Epoch 4/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 2.2991\n",
      "Epoch 00004: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 769s 154ms/step - loss: 2.2989 - val_loss: 2.0274\n",
      "Epoch 5/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 2.0609\n",
      "Epoch 00005: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 714s 143ms/step - loss: 2.0606 - val_loss: 1.3254\n",
      "Epoch 6/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.8326\n",
      "Epoch 00006: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 713s 143ms/step - loss: 1.8330 - val_loss: 3.5529\n",
      "Epoch 7/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.7396\n",
      "Epoch 00007: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 713s 143ms/step - loss: 1.7395 - val_loss: 1.2143\n",
      "Epoch 8/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.6174\n",
      "Epoch 00008: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 714s 143ms/step - loss: 1.6174 - val_loss: 0.9988\n",
      "Epoch 9/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.5482\n",
      "Epoch 00009: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 714s 143ms/step - loss: 1.5485 - val_loss: 1.1896\n",
      "Epoch 10/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.4223\n",
      "Epoch 00010: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 714s 143ms/step - loss: 1.4225 - val_loss: 1.9420\n",
      "Epoch 11/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.4052\n",
      "Epoch 00011: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 713s 143ms/step - loss: 1.4049 - val_loss: 1.0355\n",
      "Epoch 12/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.4012\n",
      "Epoch 00012: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 715s 143ms/step - loss: 1.4014 - val_loss: 1.6630\n",
      "Epoch 13/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.2864\n",
      "Epoch 00013: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 712s 142ms/step - loss: 1.2868 - val_loss: 0.8196\n",
      "Epoch 14/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.2885\n",
      "Epoch 00014: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 711s 142ms/step - loss: 1.2890 - val_loss: 1.0235\n",
      "Epoch 15/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.2644\n",
      "Epoch 00015: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 710s 142ms/step - loss: 1.2643 - val_loss: 1.8533\n",
      "Epoch 16/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.1802\n",
      "Epoch 00016: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 708s 142ms/step - loss: 1.1803 - val_loss: 1.2330\n",
      "Epoch 17/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.1827\n",
      "Epoch 00017: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 710s 142ms/step - loss: 1.1826 - val_loss: 1.2056\n",
      "Epoch 18/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.1820\n",
      "Epoch 00018: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 709s 142ms/step - loss: 1.1819 - val_loss: 0.7756\n",
      "Epoch 19/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.1374\n",
      "Epoch 00019: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 731s 146ms/step - loss: 1.1372 - val_loss: 0.8375\n",
      "Epoch 20/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.1177\n",
      "Epoch 00020: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 711s 142ms/step - loss: 1.1176 - val_loss: 0.9704\n",
      "Epoch 21/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.1308\n",
      "Epoch 00021: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 710s 142ms/step - loss: 1.1308 - val_loss: 0.8519\n",
      "Epoch 22/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.1284\n",
      "Epoch 00022: saving model to /storage/Manual Model.h5\n",
      "5000/5000 [==============================] - 721s 144ms/step - loss: 1.1282 - val_loss: 0.7881\n",
      "Epoch 23/50\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 1.0784\n",
      "Epoch 00023: saving model to /storage/Manual Model.h5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "5000/5000 [==============================] - 711s 142ms/step - loss: 1.0784 - val_loss: 0.8838\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(\"/storage/Manual Model.h5\",compile=False)\n",
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "print(\"Successfully loaded h5 model!\")\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "print(\"Successfully created callback: Monitor\")\n",
    "checkpoint = ModelCheckpoint(\"/storage/Manual Model.h5\", \n",
    "                             monitor='val_loss', verbose=1)\n",
    "print(\"Successfully created callback: Checkpoint\")\n",
    "history = model.fit_generator(train_generator, validation_data=test_generator, steps_per_epoch=5000,\n",
    "                    callbacks=[checkpoint,monitor], epochs=50, verbose = 1,\n",
    "                    initial_epoch=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded h5 model!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(\"/storage/2020-04-06(0.61).h5\",compile=False)\n",
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "print(\"Successfully loaded h5 model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_validate = pd.read_csv(\"/storage/validate.csv\", na_values=['NA', '?'])\n",
    "df_validate['filename']=\"clips-\"+df_validate[\"id\"].astype(str)+\".png\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGES_DIR = \"/storage/clips\"\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=df_validate,\n",
    "        directory=IMAGES_DIR,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"id\",\n",
    "        target_size=(256, 256),\n",
    "        class_mode='other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:48<00:00, 21.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>2.008205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>47.523621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>64.273804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>3.162733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25005</th>\n",
       "      <td>45.325871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>32.216011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>53.702774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>61.293934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>4.634710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>32.069103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           clips\n",
       "25001   2.008205\n",
       "25002  47.523621\n",
       "25003  64.273804\n",
       "25004   3.162733\n",
       "25005  45.325871\n",
       "...          ...\n",
       "29996  32.216011\n",
       "29997  53.702774\n",
       "29998  61.293934\n",
       "29999   4.634710\n",
       "30000  32.069103\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(5000)):\n",
    "    arr=np.expand_dims(np.array(Image.open(f\"/storage/clips/clips-{25001+i}.png\"))/255, 0)\n",
    "    df.loc[i+25001,\"clips\"]=model.predict(arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/notebooks/submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.45.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
